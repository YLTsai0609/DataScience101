# Object Tracking
## Naive approach
對於單點$(x,y)$來說，每個timestamp產生一個$(x,y)$，如此一來形成一個array，也可以說是函數$$C_{k}~~where~~k=1,2,3,...t$$
若
$$\frac{dc}{dt}<\epsilon$$
則為連續(即連續的定義)
Problem : 上述定義只能解決等速率時的情況，若單體具有加速度，就爆了，若每個出現在畫面中的單體，有不同的速率，同樣的爆了，因為不知道$\epsilon$怎麼定。

## kalman filtering
[Reference](https://zhuanlan.zhihu.com/p/39912633)
用於物件追蹤，雷達，軌道預測，kalman在196x年發表，用來解決火箭軌道預測的問題
核心思想主要加入了Bayesian inference，搭配物理學的運動公式，來推論下一個時間點可能的位置

#### 用途
存在不確定訊息的動態系統，kalman filtering可以針對系統的下一步要做什麼做出有根據的推測，即便有噪聲訊息干擾。

#### 優點與缺點 

優點 : 記憶體佔用小，速度快
缺點 : pass

#### 概念與數學

##### Introduction
一個可以在樹林裡四處閒逛的小機器人，為了實現導航，**機器人需要知道自己所在的位置**

機器人會有一個包含位置以及速度訊息的狀態$x_{k}$，$x$是一個$n$維度的向量，或說矩陣
$$
x_{k} = (p, v)
$$
其中$p$存放位置資訊，可能有1~3個維度，$v$ 存放速度資訊，可能有1~3個維度，與$p$具有相同維度

* 我們可以透過GPS傳感器，得知機器人位置，有定位精度的問題，我們只能知道個大概，**所以GPS提供的資訊無法足夠精準**

* 我們可以預測機器人的移動，透過控制馬達，但是控制馬達並不代表他的速度，因為可能**逆風行駛**，**輪子打滑**，**滾落顛波地形**，所以根據控制馬達的預測也無法完美

* 在**如此多外部因素**的情況下，我們能夠足夠精準的預測機器人的位置?
* 答案就是卡曼濾波

> 思考點 : 如果外部因素不會很多，例如風阻小，穩定的運動軌跡，追蹤點不會突然消失等等，我們只要有**位置**，**速度**，**加速度**，就能夠足夠準確的預測物體軌跡，所以只有在**外部因素多的時候**，加入bayesian inference的思想，進行推論，我們就不用一一計算各個外部因素帶來的影響

<img src='/images/kalman_1.png'></img>

* 暫時地，我們先假設位置$p$與速度$v$沒有相關性(這當然是不對的，我們後面可以修正回來)，並且只看一個維度
<img src='/images/kalman_2.png'></img>
* kalman filtering假設的兩個變量(as a vector)都應該是**隨機的**，並且符合**高斯分佈**，在這樣的前提下，每個變量都有一個均值$\mu$，以及一個方差$\sigma^{2}$用來描述隨機分佈的中心以及組合的不確定性
* 不過按照物理學的知識，位置和速度具有公式關係，換句話說，相關係數是1，我們有了速度，瞭解上一步的位置的情況下，且運動物體是等速前進的，我們就能夠推論位置，換句話說，在這樣的情況下相關係數是1
<img src='/images/kalman_3.png'></img>

* 從統計的觀點來看上述的圖形，我們可以說 : 在外部因素的情況下，雖然有速度無法100%精確的預測接下來的位置，但是有足夠高的相關性幫助我們縮小接下來可能的位置範圍，或許是一個區間估計
* 而我們怎麼使用這個高度相關性的物理量呢? 統計上使用Covariance matrix來捕捉correlation
$$
Covariance~matrix~= \Sigma_{ij}
$$
在此例子中, $i,j=1$表示位置, $i,j=2$表示速度，$\Sigma_{ij}$是一個對稱，且semi positive(半正定)矩陣
<img src='/images/kalman_4.png'></img>

##### 用矩陣描述問題
在$k$時刻下 : 
最佳估計值$\hat{x}$以及Covariance Matrix $P_{k}$
$$
\hat{x_{k}} = {position \brack velocity}, ~~
P_{k} = {\Sigma_{pp}~\Sigma_{pv} \brack \Sigma_{vp}~\Sigma_{vv}}
$$
> ? 這裡的$\hat{x_{k}}$是否是$x_{k}$？還是一個是預測一個是True?

我們想要透過查看當前狀態$k-1$時刻，來預測下一個狀態$k$時刻，因為是透過Bayesian inference，所以不是點估計，而是區間估計(一個機率分佈)
<img src='/images/kalman_5.png'></img>

我們透過矩陣$F_{k}$來表示預測這個步驟

<img src='/images/kalman_6.png'></img>

矩陣$F_{k}$長怎樣呢?
在向量方程式中我們透過速度的定義能夠得知
$$
p_{k} = p_{k-1} + v_{k-1}\Delta t
$$
$$
v_{k} = v_{k-1}.....suppose~no~change~here
$$

矩陣形式
$$
\hat{x_{k}} = {{1} ~{\Delta t} \brack {1}~~{0}} = F_{k}\hat{x}_{k-1}
$$

這個預測矩陣$F_{k}$能夠給出平均值改變的位置，但是Covanriance matrix的更新方法呢? 這是另一間我們要處理的

##### 題外話 : 一項矩陣操作
$$
cov(x) = \Sigma
$$
$$
cov(Ax) = A \Sigma A ^{T}
$$
如果我們對一個矩陣取covariance matrix, 那麼在對其進行伸縮，旋轉時，再娶covraiance時，等價於右式的操作

##### 回到問題，新的Covariance matrix
基本上就是所謂的$Cov(F_{k}\hat{x}_{k-1})$，把剛剛講的矩陣操作帶進來
我們就可以得到基於k-1時刻的資訊，透過預測矩陣F_{k}所得到的mean以及covariance
$$
\hat{x}_{k} = F_{k}\hat{x}_{k-1}
$$
$$
P_{k} = F_{k}P_{k-1}F^{T}_{k}
$$

##### 加入加速度
在剛剛的預測式中，我們只考慮的速度，是為了方便講解，現在我們加入加速度，在每個時刻下，物體運動都能夠假設為是一個等加速度運動

$$
p_{k} = p_{k-1} + v_{k-1}\Delta t + \frac{1}{2}a\Delta t^{2}~~~~~~~~~~~(1)
$$
$$
v_{k} = v_{k-1} + a\Delta t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(2)
$$

寫成矩陣形式 

$$
\hat{x}_{k} = F_{k}\hat{x}_{k-1} + {\frac{\Delta t^{2}}{2} \brack{\Delta t}}a = F_{k}\hat{x}_{k-1} + B_{k}u_{k}
$$
$$
{\frac{\Delta t^{2}}{2} \brack{\Delta t}} = B_{k}, a = u_{k}  
$$
此加速度$a$在文章中被稱之為外部因素是因為，
在動力學系統中，加速度$a$通常都是由操縱者調整了油門或是馬達，是根據
$$
F=ma
$$

> 所以在文章中稱 $B_{k}$ 為控制矩陣，而$u_{k}$ 為控制向量，若在face detection這個場景中，由於我們沒有給定的外力，人出現加速度是經常性的，那 $B_{k}$ 對我們來說就當作是預測矩陣2即可，同樣的 $u_{k}$ 也會是變動的，因為每個人的加速度可能不同。

在上述兩條運動方程式中，我們就能夠足夠準確的預測接下來物體的軌跡，除非，觀測到的**加速度不太準確**，換句話說，我們收到的加速度訊號並非物體實際上的加速度，這也就是所有外部因素的總和，kalman filter對於這一點，透過這樣的方式處理:

> 在每個預測步驟後加上一些新的不確定性，藉以模擬現場情況的所有不確定性

<img src='/images/kalman_7.png'></img>

如上圖所示，加上外部不確定性之後，$\hat{x}_{k-1}$的每個預測狀態都可能會移到紫色高斯分佈的地方，而這樣的高斯分佈具有Covariance Matrix $Q_{k}$，換句話說，我們預測的均值仍然是在紫色高斯分佈的中心，然而Covarance會加大


$$
\hat{x}_{k} = F_{k}\hat{x}_{k-1}
$$
$$
P_{k} = F_{k}P_{k-1}F^{T}_{k} + Q_{k}
$$

在這一步，我們再一次釐清各個符號所代表的意義

* $\hat{x}_{k}$ : 當前的狀態向量，裡面包含了位置以及速度，位置，速度的維度可能為1, 2, 3
* $\hat{x}_{k-1}$ : 上一步的狀態向量，說明和上一條相同
* $F_{k}$ 預測矩陣，裡面描述了速度的定義以及等加速度情況下的運動公式，掌握位置$p$以及時間間隔$\Delta t$的情況下，**理論上**我們能夠準確的預測下一時刻的位置，速度
* $P_{k}$ : 當前的Covariance matrix : 現時情況下共變數的部分不可能是1，基本上會考慮所有noise, 阻力，路面顛波等等效應，我們可以期待對角線為1，共變數部分相當高，但是不會完全是1，而共變數的值越小，顯示了noise, 阻力, 路面顛波等其他效應越大
* $F_{k}P_{k-1}F^{T}_{k}$ 基本上是從 $Cov(F_{k}P_{k-1})$這個步驟變來的，而$Cov(F_{k}P_{k-1})$的意義就是將$k-1$時刻的位置及速度不確定性預測到當前時刻$k$
* $Q_{k}$ 測量到的加速度未必是物體真實的加速度，特別在一個複雜的動力學系統，可能要計算各種齒輪間的摩擦力，油品所降低的摩擦力等等，因此加入一個noise項，這項可以透過參數調整來更match產品實際環境


##### 談談測量狀況
* 回顧我們最一開始說的，如果定位精度是10米，那我們讀取到的數值事實上跟機器人的實際位置是有落差的，而且我們也可以說，多種正確位置都能夠產生同樣的sensor讀數

<img src='/images/kalman_8.png'></img>

這裡我們假設sensor的狀態傳遞基本上經過一個讀取矩陣$H_{k}$來反應，
當然地，如果是100%完美反應物體位置以及速度的情況下 $H_{k} = I$
我們也就不需要什麼 kalman filter了，直接$F=ma$算出來搞定
> 這個地方假設了sensor的讀取矩陣$H_{k}$不隨時間改變，這不是事實，大家都知道sensor過久了就會越來越不準，然後越來越壞掉
> 並且我們能夠有一個相對直覺的想像，$H_{k} ～ I$則表示我們精確度非常高，sensor能夠非常精確的反應位置以及速度，反之和$I$越不像，表示定位精確度相對差

<img src='/images/kalman_9.png'></img>

$$
z_{k} = H_{k}\hat{x}_{k}
$$

$$
R_{k} = H_{k}P_{k}H^{T}_{k}
$$

我們把當前時刻sensor收到的數值同樣假設為服從一個分佈，讀數分佈均值為$z_{k}$，Covarance為$R_{k}$

<img src='/images/kalman_10.png'></img>

現在我們就有兩塊高斯分佈
* 一塊是上一個時刻點的狀態$p$裡面包含了位置以及外力產生的加速度$u$
* 一塊是當前時刻的狀態經過sensor傳送回來的分佈
在多重外力因素下，上面兩塊分佈都不太準，我們打算怎麼做?
我們打算娶他們的交集，那就是最準的了!

<img src='/images/kalman_11.png'></img>

並且在數學上，兩個高斯分佈相乘，仍然是高斯分佈啊!!!

<img src='/images/kalman_12.png'></img>

所以總結上述兩種訊息，五們就能夠更新當前的預測軌跡!

> 在這裡也透露出了kalman filter的價值所在，當你的sensor定位精度以及速度計，加速度計測量不夠準確的情況下，我們就需要用到! 透過上一個時刻的資訊加上運動學公式來融合當前時刻的測量值，得到一個更精確的運動軌跡，反過來說，sensor足夠準的情況下，把kalman filter丟了吧，把$F=ma$寫成矩陣形式然後算位置即可

##### 高斯分佈的相乘

* 剛剛兩個高斯分佈的相乘，得到新的mean以及variance，就能夠把mean取出來當作預測值!
這裡的符號可能跟上面有一些搞混，要小心!
標準一維高斯分佈，variance $\sigma^{2}$, mean $\mu$, 隨機變數 $x$
$$
N(x, \mu, \sigma) = \frac{1}{\sigma \sqrt{2 \pi}}e^{- \frac{(x-\mu)^{2}}{2\sigma^{2}}}
$$

兩個高斯曲線相乘?

<img src='/images/kalman_13.png'></img>

* 只是看起來很複雜，分數相乘 -> 直接相乘, 指數相乘 -> 指數部分加起來，然後再重新整理成符合$
N(x, \mu, \sigma) = \frac{1}{\sigma \sqrt{2 \pi}}e^{- \frac{(x-\mu)^{2}}{2\sigma^{2}}}
$的形式，就能夠得到$\mu'$以及$\sigma'^{2}$

基本上我們推導一下，會得到
$$
\mu' = \mu_{0} + \frac{\sigma^{2}_{0}(\mu_{1} - \mu_{0})}{\sigma^{2}_{0} + \sigma^{2}_{1}}
$$

$$
\sigma'^{2} = \sigma^{2}_{0} -  \frac{\sigma^{4}_{0}}{\sigma^{2}_{0} + \sigma^{2}_{1}}
$$

賣弄數學的時候到了，如果我們令
$$
k = \frac{\sigma^{2}_{0}}{\sigma^{2}_{0} + \sigma^{2}_{1}}
$$

則mean以及variance會得到

$$
\mu' = \mu_{0} + k(\mu_{1} - {\mu_{0}})
$$

$$
\sigma'^{2} = \sigma^{2}_{0} - k\sigma^{2}_{0}
$$

$$where~~0 \leq k \leq 1$$

##### 有什麼物理意義? 
新的mean會存在一個修正量，而這個修正量就是$k$乘上兩個分佈的mean差值
新的varaicne同樣會存在一個修正量，而這個修正量是$k$乘上原本的variance，這個k看起來具有明確的定義，我們把它稱作為**kalman gain(卡曼增益)**，並且可以注意到的地方是，vairance變小了，這正是我們想要的結果，透過上一刻$k-1$的資訊，讓我們當前時刻$k$的預測更貼近物體真實的狀態

##### 來吧寫成矩陣形式
在多維度的高斯分佈中
$$
K = \Sigma_{0}(\Sigma_{0} + \Sigma_{1})^{-1}
$$
$$
\mu' = \mu + K(\mu_{1} - \mu_{0})
$$
$$
\Sigma' = \Sigma_{0} - K\Sigma_{0}
$$
矩陣K即為kalman gain (卡曼增益)


##### Put it all together
截至目前為至，我們有第$k-1$時刻矩陣$(\mu_{0}, \Sigma_{0}) = (H_{k-1}\hat{x}_{k-1}, H_{k-1}P_{k-1}H^{T}_{k-1})$預測的分佈
以及第$k$時刻透過sensor讀取到的讀數$(\mu_{1}, \Sigma_{1}) = (z_{k}, R_{k})$
將兩式帶入上述推倒

卡曼增益 : 
$$
K = H_{k-1}P_{k-1}H^{T}_{k-1}(H_{k-1}P_{k-1}H^{T}_{k-1} + R_{k})^{-1}
$$

時刻$k$之狀態以及Covarance Matrix
$$
\hat{x}_{k}' = \hat{x}_k + K(z^{k} + H_{k-1}\hat{x}_{k-1})
$$
$$
P_{k}' = P_{k}-K'H_{k}P_{k}
$$

<img src='/images/kalman_14.jpg'></img>


#### Tuning


#### 實作

#### 其他應用
狀態矩陣$x$可以放的是位置與速度，但是也可以放液體體積，引擎溫度，觸摸板上指標的位置，或是其他數據，基本上配上一個一階微分的物理量

#### Math 
(semi-positive) 半正定矩陣 : 
