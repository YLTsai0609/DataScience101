# P-Value
## 情境
* 以KKBOX的每月流失為例，我們有一個假設(Hypothesis $ H_0 $)，聲稱在非新客(連續續約1年以上)的使用者流失率介在5% ~ 10%之間
好的，那我們直接來進行抽樣
* 假設檢定中有3個重要因素，統計模型(真理)、null hypothsis、資料
* 統計模型 : $X_i ～ Bernoulli(\theta)$，每個人流失與否是獨立的，不會互相影響
* 資料 : 隨機抽樣1000個非新客使用者，蒐集到了樣本$(X_1, X_2, ..., X_{1000})$
* 假設 : 我們想要利用資料證明 null hypothsis為True / False
考慮兩個Dimension如下

||$H_0$ True|$H_0$ False|
|-|---------|-----------|
|不拒絕 $H_0$|正確|Type II error|
|拒絕 $H_0$|Type I error|正確|

由於每一次抽出的樣本都會不同，比如說：抽樣出來的使用者1000個都不一樣，我們無法保證每一次抽出的樣本都能反映出真實情況，因此進行假設檢定時可能會出現兩種錯誤，這也對應到分類問題的 False Positive、Flase Negtive
* Type I Error 其實流失率在5% ~ 10%，但我們不認為流失率在5% ~ 10%(false positive)
* Ｔype II Error 其實流失率不在在5% ~ 10%之內，但我們認為在區間內
我們當然希望 Type I Error / Type II Error 都越小越好，但其實沒辦法，通常一個高，另一個就會低(就跟fp, fn一樣)
<img src='./images/Type1 Error Rejection Region.png'></img>
* 由於我們是抽樣調查，因此我們抽出1000個人之後計算流失率，可能會是5%, 7%, 3% 也可能是25%，這個抽樣機率分佈我們假設屬於高斯分佈
* RR右邊的紅色，底線就是其實確實流失率在5% ~ 10%之間，但是我們抽樣的運氣特差，抽出來高達25%，不過其實我們只要重複同樣抽樣過程，就會察覺真實流失率確實在5~10%之間，此時我們有錯誤的推斷，為Type I Error，至於藍色為Type II Error
* 假設我們今天算出來，流失率是25%，那我們就要回到原本的統計分佈，問一個問題，在$H_{0}$的情況下，出現流失率是25%的機率是多少?，這是一個高斯分佈計算機率的問題，我們可以透過統計算體幫我們計算，假設我們今天算出來，流失率是25％的機率是2%，這個2%就是所謂的p-value
* 意思就是說，我們收集到流失率是25%的樣本的機率是2%，這基本上算是蠻不可能的，極有可能其實原本流失率根本就不是5~10%，而是更高，而我們就會設定一個機率值作為threshold，當過了這個threshold，我們就認定原本的假設是不太可能的，這個值常常會是5%，事實上我們也可以設1%(表示我們非常嚴謹)，或是90%, 80%(表示我們希望寬鬆一點)，基本上機率低於$\alpha$，我們會說，達到統計顯著，我們傾向拒絕原本的假設
* 而$\alpha$值的選取，取決於我們對於Type I Error及 Type II Error所能承受的風險
* 在這個案例中，我們通常無法承受實際上流失率更高，但是我們認為其實是5~10%的這種錯誤，也就是Type II Error，因此我們會希望Type II Error的機率盡量小，此時我們或許會設定$\alpha = 0.1, 0.2$。
* 在這個案例中，由於判定流失的抽樣並不會有很高的成本，我們可以多次進行抽樣，譬如每個月都抽一次1000人，來計算流失比例，當計算流失比例時為一個點估計問題，在抽樣次數多次的情況下，根據**中央極限定理**，抽樣分佈會接近高斯分佈，且我們的比例的標準差會以$\frac{p} {n^{1/2}}$ 縮小，這讓我們能夠在抽樣次數夠多的情況下推斷流失比率


# Ｍath talk : Hypothesis testing 
  
  我們希望推論參數 $\theta$ 落在區域 $\Theta$ 即 $\theta \in \Theta $
  我們希望根據蒐集到的資料，驗證上述假設的真實性，此時這個假設會被稱為null hypothesis $H_0$，同時會存在另一個alternatvie hypothesis $H_1$ 是與null hypothesis完全相反的假設，即:
  參數 $\theta 並不落在區域 \Theta， \theta \notin \Theta$
  由於這是一個二分法，因此，真實市價只會有兩種可能，即$H_0$為真或是$H_0$為假，同時，我們觀察資料後也只能得到兩種結果，「資料有充分證據說明$H_0$為假」以及「資料沒有充分證據證明 $H_0$ 為假」。
## 最強檢定力檢定
* 由於兩樣error會互相影響，統計學家決定，不如我們先**限制其中一項錯誤的機率，再去看看要如何找出拒絕的標準**，因此我們通常會先確保Type I Error的機率不會超過一個theshold $\alpha$，一般$\alpha = 1%, 5%, 10% $ 這只是習慣，接著我們將拒絕null hypothsis的標準，寫成一個區域的形式，稱為拒絕域 $RR$(rejection region)
當我們蒐集到的樣本落於RR時，我們便會拒絕$H_0$
* 因此，當Type I Error的機率 $$P(X_1,...X_{1000}) \in RR | H_{0} \ is \ true <= \alpha$$
* 一旦$\alpha$被決定之後，我們就可以決定 Type II error的機率 $\beta$，此時，我們將一個假設檢定的檢定力(power)定義為 $1 - \beta$，統計學家期待能夠在控制Type I error的情況下，使得 $\beta$最小，這樣的檢定方法，被稱為「最強檢定力檢定」(most powerful test)
## 要點
* P-value表示得就是機率，而假設檢定是一個True, False的統計推論，$\alpha$是拒絕原假設的threshold，$\beta$是 Type II Error的機率，我們必須針對每個case思考我們能夠接受怎樣的風險，進而訂定每個實驗的$\alpha$
* 有了高斯分布的參數，我們就可以normolize回去，算Z-score，然後再估計大於該值的機率為何
